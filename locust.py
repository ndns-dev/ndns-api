# load_test_patterns.py
import json
import time
from locust import HttpUser, task, between, events
import logging
import statistics
from collections import defaultdict
import hashlib
import glob
import os

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹œê°„ê³¼ ì‘ë‹µ ë°ì´í„°ë¥¼ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜
test_start_time = None
response_times = []
total_requests = 0
response_patterns = defaultdict(lambda: {
    "count": 0,
    "first_seen": None,
    "last_seen": None,
    "sample": None,
    "response_times": [],
    "errors": []
})

def get_response_hash(response_data):
    """ì‘ë‹µ ë°ì´í„°ì˜ í•´ì‹œê°’ì„ ìƒì„±"""
    try:
        # ì •ë ¬ëœ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì¼ê´€ëœ í•´ì‹œ ìƒì„±
        json_str = json.dumps(response_data, sort_keys=True)
        return hashlib.md5(json_str.encode()).hexdigest()[:8]
    except Exception as e:
        return f"error_{str(e)[:20]}"

def get_next_file_number():
    """ë‹¤ìŒ íŒŒì¼ ë²ˆí˜¸ë¥¼ ì°¾ìŒ"""
    files = glob.glob("performance_summary*.json")
    if not files:
        return 1
    
    numbers = []
    for file in files:
        try:
            num = int(file.replace("performance_summary", "").replace(".json", ""))
            numbers.append(num)
        except ValueError:
            continue
    
    return max(numbers) + 1 if numbers else 1

class ApiUser(HttpUser):
    # í…ŒìŠ¤íŠ¸í•  ê¸°ë³¸ URL (k6ì˜ BASE_URLê³¼ ë™ì¼)
    # host = "http://localhost:8085"
    # host = "https://route.ndns.site"
    host = "http://182.217.147.28:8085"
    # OCR ì²˜ë¦¬ ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ì‚¬ìš©ì ëŒ€ê¸° ì‹œê°„ì„ 12-15ì´ˆë¡œ ì„¤ì •
    wait_time = between(12, 15)

    SEARCH_QUERY = "ë³‘ì  ë§›ì§‘"

    def on_start(self):
        """ì‚¬ìš©ì ì„¸ì…˜ì´ ì‹œì‘ë  ë•Œ í˜¸ì¶œ"""
        pass

    def on_stop(self):
        """ì‚¬ìš©ì ì„¸ì…˜ì´ ì¢…ë£Œë  ë•Œ í˜¸ì¶œ"""
        pass

    @task
    def search_api(self):
        global total_requests
        total_requests += 1
        start_time = time.time()
        
        with self.client.get(
            f"/api/v1/search?query={self.SEARCH_QUERY}&limit=10&offset=0",
            name="/api/v1/search",
            catch_response=True
        ) as response:
            response_time = time.time() - start_time
            response_times.append(response_time)

            try:
                if response.status_code == 200:
                    response_data = response.json()
                    pattern_hash = get_response_hash(response_data)
                else:
                    # ì—ëŸ¬ ì‘ë‹µë„ íŒ¨í„´ìœ¼ë¡œ ì²˜ë¦¬
                    pattern_hash = f"error_{response.status_code}"
                    response_data = {"error": f"HTTP {response.status_code}: {response.text}"}
            except json.JSONDecodeError as e:
                pattern_hash = "error_json_decode"
                response_data = {"error": f"JSON ë””ì½”ë”© ì—ëŸ¬: {str(e)}"}
            except Exception as e:
                pattern_hash = f"error_unexpected_{type(e).__name__}"
                response_data = {"error": f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {str(e)}"}

            # ëª¨ë“  ìš”ì²­ì— ëŒ€í•´ íŒ¨í„´ ì •ë³´ ì—…ë°ì´íŠ¸
            pattern = response_patterns[pattern_hash]
            if pattern["count"] == 0:
                pattern["first_seen"] = time.time()
                pattern["sample"] = response_data
                logger.info(f"\nğŸ†• ìƒˆë¡œìš´ ì‘ë‹µ íŒ¨í„´ ë°œê²¬! (íŒ¨í„´: {pattern_hash})")
                
            pattern["count"] += 1
            pattern["last_seen"] = time.time()
            pattern["response_times"].append(response_time)

            # OCR ì²˜ë¦¬ ì‹œê°„ì´ ë„ˆë¬´ ê¸¸ ê²½ìš° (15ì´ˆ ì´ˆê³¼) ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
            if response_time > 15:
                error_msg = f"ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {response_time:.2f}ì´ˆ"
                pattern["errors"].append(error_msg)
                response.failure(error_msg)
            elif response.status_code != 200:
                error_msg = f"HTTP {response.status_code}: {response.text}"
                pattern["errors"].append(error_msg)
                response.failure(error_msg)
            else:
                response.success()

# --- Locust ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
def on_request_completion(request_type, name, response_time, response_length, response, exception, **kwargs):
    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ì—ì„œëŠ” íŒ¨í„´ ì¹´ìš´íŒ…ì„ í•˜ì§€ ì•Šê³  ë¡œê¹…ë§Œ ìˆ˜í–‰
    if name == "/api/v1/search" and response.status_code == 200 and exception is None:
        try:
            response_body = response.json()
            logger.debug(f"Response received: {json.dumps(response_body, indent=2, ensure_ascii=False)}")
        except json.JSONDecodeError:
            logger.error(f"Failed to decode JSON in request completion handler: {response.text}")
        except Exception as e:
            logger.error(f"Error in request completion handler: {e}")

# init ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ëŠ” Locust í™˜ê²½ì´ ì´ˆê¸°í™”ëœ í›„ì— í˜¸ì¶œë©ë‹ˆë‹¤.
# ì´ ì•ˆì—ì„œ on_request_completion í•¨ìˆ˜ë¥¼ environment.events.requestì— ë“±ë¡í•©ë‹ˆë‹¤.
@events.init.add_listener
def on_locust_init(environment, **kwargs):
    # request_success ëŒ€ì‹  request ì´ë²¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    environment.events.request.add_listener(on_request_completion)

# í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹œ í˜¸ì¶œë˜ëŠ” ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
@events.test_start.add_listener
def on_test_start(**kwargs):
    global test_start_time, response_times, response_patterns, total_requests
    test_start_time = time.time()
    response_times = []
    total_requests = 0
    response_patterns.clear()
    logger.info("ğŸš€ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")

# í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ì‹œ í˜¸ì¶œë˜ëŠ” ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
@events.test_stop.add_listener
def on_test_stop(**kwargs):
    if not response_times:
        logger.info("ìˆ˜ì§‘ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return

    # ê¸°ë³¸ ì„±ëŠ¥ í†µê³„ ê³„ì‚°
    avg_response_time = statistics.mean(response_times)
    median_response_time = statistics.median(response_times)
    p95_response_time = statistics.quantiles(response_times, n=20)[18]  # 95th percentile
    min_response_time = min(response_times)
    max_response_time = max(response_times)

    # ì‘ë‹µ íŒ¨í„´ ë¶„ì„
    patterns_summary = []
    pattern_total_count = sum(pattern["count"] for pattern in response_patterns.values())
    
    for pattern_id, data in response_patterns.items():
        pattern_avg_time = statistics.mean(data["response_times"]) if data["response_times"] else 0
        
        patterns_summary.append({
            "pattern_id": pattern_id,
            "count": data["count"],
            "percentage": f"{(data['count'] / total_requests * 100):.1f}%",
            "avg_response_time": f"{pattern_avg_time:.2f}s",
            "first_seen": time.strftime('%Y-%m-%dT%H:%M:%S%Z', time.localtime(data["first_seen"])),
            "last_seen": time.strftime('%Y-%m-%dT%H:%M:%S%Z', time.localtime(data["last_seen"])),
            "sample": data["sample"],
            "error_count": len(data["errors"]),
            "recent_errors": data["errors"][-5:] if data["errors"] else []  # ìµœê·¼ 5ê°œ ì—ëŸ¬ë§Œ ì €ì¥
        })

    # ê²°ê³¼ ìš”ì•½
    summary = {
        "performance_metrics": {
            "average_response_time": f"{avg_response_time:.2f}s",
            "median_response_time": f"{median_response_time:.2f}s",
            "p95_response_time": f"{p95_response_time:.2f}s",
            "min_response_time": f"{min_response_time:.2f}s",
            "max_response_time": f"{max_response_time:.2f}s",
            "total_requests": total_requests,
            "pattern_total_count": pattern_total_count
        },
        "test_duration": {
            "start_time": time.strftime('%Y-%m-%dT%H:%M:%S%Z', time.localtime(test_start_time)),
            "end_time": time.strftime('%Y-%m-%dT%H:%M:%S%Z', time.localtime(time.time())),
            "duration_seconds": f"{time.time() - test_start_time:.2f}"
        },
        "response_patterns": patterns_summary
    }

    # ê²°ê³¼ ì¶œë ¥
    logger.info("\nğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìš”ì•½")
    logger.info("===================")
    logger.info(f"ì´ ìš”ì²­ ìˆ˜: {total_requests}")
    logger.info(f"íŒ¨í„´ë³„ ì‘ë‹µ í•©ê³„: {pattern_total_count}")
    logger.info(f"í‰ê·  ì‘ë‹µ ì‹œê°„: {summary['performance_metrics']['average_response_time']}")
    logger.info(f"ì¤‘ê°„ê°’ ì‘ë‹µ ì‹œê°„: {summary['performance_metrics']['median_response_time']}")
    logger.info(f"95ë²ˆì§¸ ë°±ë¶„ìœ„ ì‘ë‹µ ì‹œê°„: {summary['performance_metrics']['p95_response_time']}")
    logger.info(f"ìµœì†Œ ì‘ë‹µ ì‹œê°„: {summary['performance_metrics']['min_response_time']}")
    logger.info(f"ìµœëŒ€ ì‘ë‹µ ì‹œê°„: {summary['performance_metrics']['max_response_time']}")
    
    logger.info("\nğŸ“‹ ì‘ë‹µ íŒ¨í„´ ë¶„ì„")
    logger.info("===================")
    for pattern in patterns_summary:
        pattern_type = "ì„±ê³µ" if not pattern["pattern_id"].startswith("error") else "ì‹¤íŒ¨"
        logger.info(f"\níŒ¨í„´ {pattern['pattern_id']} ({pattern_type}):")
        logger.info(f"  ë°œìƒ íšŸìˆ˜: {pattern['count']} ({pattern['percentage']})")
        logger.info(f"  í‰ê·  ì‘ë‹µ ì‹œê°„: {pattern['avg_response_time']}")
        if pattern["error_count"] > 0:
            logger.info(f"  ì—ëŸ¬ íšŸìˆ˜: {pattern['error_count']}")
            logger.info("  ìµœê·¼ ì—ëŸ¬:")
            for error in pattern["recent_errors"]:
                logger.info(f"    - {error}")

    # ë‹¤ìŒ íŒŒì¼ ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
    next_num = get_next_file_number()
    filename = f"performance_summary{next_num}.json"

    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nâœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ {filename} íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
