# load_test_patterns.py
import json
import time
from locust import HttpUser, task, between, events
from collections import defaultdict
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì‘ë‹µ íŒ¨í„´ì„ ì €ì¥í•  ì „ì—­ ë”•ì…”ë„ˆë¦¬ (Locustì˜ Master/Worker ëª¨ë“œì—ì„œ ì§‘ê³„ë  ë•Œ ì‚¬ìš©)
# defaultdictë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ íŒ¨í„´ì´ ë“±ì¥í•˜ë©´ ìë™ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ë„ë¡ ì„¤ì •
response_patterns = defaultdict(lambda: {
    "count": 0,
    "firstSeen": None,
    "lastSeen": None,
    "sampleResponse": {}
})

# ì‘ë‹µ JSON ë³¸ë¬¸ì„ ì¼ê´€ëœ ë¬¸ìì—´(í•´ì‹œ)ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
# JSON í‚¤ ìˆœì„œê°€ ì¤‘ìš”í•˜ì§€ ì•Šë‹¤ë©´, sort_keys=Trueë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥
def canonicalize_json(json_data):
    return json.dumps(json_data, sort_keys=True, ensure_ascii=False)

class ApiUser(HttpUser):
    # í…ŒìŠ¤íŠ¸í•  ê¸°ë³¸ URL (k6ì˜ BASE_URLê³¼ ë™ì¼)
    host = "http://localhost:8085"
    # ê° ìš”ì²­ ì‚¬ì´ì— 1ì´ˆ ëŒ€ê¸° (k6ì˜ sleep(1)ê³¼ ìœ ì‚¬)
    wait_time = between(1, 1)

    SEARCH_QUERY = "ë³‘ì  ë§›ì§‘"

    @task
    def health_check(self):
        self.client.get("/health", name="/health") # nameìœ¼ë¡œ ìš”ì²­ì„ ê·¸ë£¹í™”í•˜ì—¬ í†µê³„ì— í‘œì‹œ

    @task
    def search_api(self):
        # ê²€ìƒ‰ API í˜¸ì¶œ
        response = self.client.get(
            f"/api/v1/search?query={self.SEARCH_QUERY}&limit=10&offset=0",
            name="/api/v1/search" # nameìœ¼ë¡œ ìš”ì²­ì„ ê·¸ë£¹í™”í•˜ì—¬ í†µê³„ì— í‘œì‹œ
        )

        if response.status_code == 200:
            try:
                # ì‘ë‹µ ë³¸ë¬¸ íŒŒì‹±
                response_body = response.json()
                # ì‘ë‹µ ë³¸ë¬¸ì„ ì •ê·œí™”ëœ JSON ë¬¸ìì—´ë¡œ ë³€í™˜ (íŒ¨í„´ ì‹ë³„ìš©)
                pattern_hash = canonicalize_json(response_body)

                # í˜„ì¬ ì‹œê°„ ê¸°ë¡ (ì—¬ê¸°ì„œëŠ” ì§ì ‘ì ì¸ ì‚¬ìš©ì€ ì—†ì§€ë§Œ, on_request_completionì—ì„œ ì‚¬ìš©ë  ìˆ˜ ìˆìŒ)
                current_time = time.time()

                # ì‘ë‹µ íŒ¨í„´ ì§‘ê³„ëŠ” on_request_completion í•¸ë“¤ëŸ¬ì—ì„œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
                # ì´ task ë‚´ë¶€ì—ì„œëŠ” HTTP ìš”ì²­ ìì²´ì˜ ì„±ê³µ ì—¬ë¶€ë§Œ í™•ì¸í•©ë‹ˆë‹¤.

            except json.JSONDecodeError:
                logger.error(f"Failed to decode JSON from response: {response.text}")
            except Exception as e:
                logger.error(f"Error processing response: {e}")
        else:
            logger.error(f"Search API returned status {response.status_code}: {response.text}")

# --- Locust ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
# on_request_completion í•¨ìˆ˜ëŠ” ì´ì œ ì¼ë°˜ í•¨ìˆ˜ë¡œ ì •ì˜ë©ë‹ˆë‹¤.
# request ì´ë²¤íŠ¸ì— ì´ í•¨ìˆ˜ë¥¼ ë“±ë¡í•˜ì—¬ ì„±ê³µ/ì‹¤íŒ¨ ìš”ì²­ ëª¨ë‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.
def on_request_completion(request_type, name, response_time, response_length, response, exception, **kwargs):
    # 'request' ì´ë²¤íŠ¸ëŠ” ì„±ê³µ/ì‹¤íŒ¨ ëª¨ë‘ì— ëŒ€í•´ ë°œìƒí•˜ë¯€ë¡œ,
    # ì„±ê³µí•œ ê²€ìƒ‰ API ìš”ì²­ì— ëŒ€í•´ì„œë§Œ íŒ¨í„´ì„ ì§‘ê³„í•©ë‹ˆë‹¤.
    if name == "/api/v1/search" and response.status_code == 200 and exception is None:
        try:
            response_body = response.json()
            pattern_hash = canonicalize_json(response_body)
            
            # ì‘ë‹µ íŒ¨í„´ ì—…ë°ì´íŠ¸
            if response_patterns[pattern_hash]["count"] == 0:
                response_patterns[pattern_hash]["firstSeen"] = time.time()
                response_patterns[pattern_hash]["sampleResponse"] = response_body # ìƒ˜í”Œ ì‘ë‹µ ì €ì¥ (ë„ˆë¬´ í¬ë©´ ë¬¸ì œ)
                logger.info(f"\nğŸ†• New response pattern found! (Hash: {pattern_hash[:30]}...)")
                logger.info(f"Sample response: {json.dumps(response_body, indent=2, ensure_ascii=False)}")
                logger.info("-------------------------------------")
            
            response_patterns[pattern_hash]["count"] += 1
            response_patterns[pattern_hash]["lastSeen"] = time.time()

        except json.JSONDecodeError:
            logger.error(f"Failed to decode JSON in request completion handler: {response.text}")
        except Exception as e:
            logger.error(f"Error in request completion handler: {e}")

# init ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ëŠ” Locust í™˜ê²½ì´ ì´ˆê¸°í™”ëœ í›„ì— í˜¸ì¶œë©ë‹ˆë‹¤.
# ì´ ì•ˆì—ì„œ on_request_completion í•¨ìˆ˜ë¥¼ environment.events.requestì— ë“±ë¡í•©ë‹ˆë‹¤.
@events.init.add_listener
def on_locust_init(environment, **kwargs):
    # request_success ëŒ€ì‹  request ì´ë²¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    environment.events.request.add_listener(on_request_completion)


# í…ŒìŠ¤íŠ¸ê°€ ì¢…ë£Œë  ë•Œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜
@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    logger.info("\nğŸ“Š Test Summary for Response Patterns")
    logger.info("======================================")

    total_search_requests = 0
    for pattern_info in response_patterns.values():
        total_search_requests += pattern_info["count"]

    if not response_patterns:
        logger.info("No search API responses collected for pattern analysis.")
        return

    # ê²°ê³¼ ìš”ì•½ ë°ì´í„° ì¤€ë¹„
    summary_data = {
        "query": ApiUser.SEARCH_QUERY,
        "total_search_requests": total_search_requests,
        "total_unique_patterns": len(response_patterns),
        "test_start_time": time.strftime('%Y-%m-%dT%H:%M:%S%Z', time.localtime(environment.start_time)),
        "test_end_time": time.strftime('%Y-%m-%dT%H:%M:%S%Z', time.localtime(time.time())),
        "patterns": []
    }

    # ê° íŒ¨í„´ ì •ë³´ ì¶”ê°€
    label_index = 0
    for pattern_hash, pattern_info in response_patterns.items():
        # íŒ¨í„´ ë ˆì´ë¸”ì€ ë‹¨ìˆœíˆ ìˆœë²ˆìœ¼ë¡œ ë¶€ì—¬
        label_index += 1

        summary_data["patterns"].append({
            "label": f"Pattern {label_index}",
            "count": pattern_info["count"],
            "percentage": f"{((pattern_info['count'] / total_search_requests) * 100):.2f}%" if total_search_requests > 0 else "0.00%",
            "firstSeen": time.strftime('%Y-%m-%dT%H:%M:%S%Z', time.localtime(pattern_info["firstSeen"])) if pattern_info["firstSeen"] else None,
            "lastSeen": time.strftime('%Y-%m-%dT%H:%M:%S%Z', time.localtime(pattern_info["lastSeen"])),
            "responseSample": pattern_info["sampleResponse"]
        })
        
        logger.info(f"\nğŸ· Pattern {label_index}:")
        logger.info(f"   Count: {pattern_info['count']} times")
        logger.info(f"   Percentage: {((pattern_info['count'] / total_search_requests) * 100):.2f}%")
        logger.info(f"   First Seen: {time.strftime('%Y-%m-%dT%H:%M:%S%Z', time.localtime(pattern_info['firstSeen'])) if pattern_info['firstSeen'] else 'N/A'}")
        logger.info(f"   Last Seen: {time.strftime('%Y-%m-%dT%H:%M:%S%Z', time.localtime(pattern_info['lastSeen']))}")
        logger.info(f"   Sample Response: {json.dumps(pattern_info['sampleResponse'], indent=2, ensure_ascii=False).splitlines()[0]}...")


    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    output_filename = "response_patterns_summary.json"
    with open(output_filename, "w", encoding="utf-8") as f:
        json.dump(summary_data, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nâœ… Response patterns summary saved to {output_filename}")
